{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contains_header = False\n",
    "dev_mode = False\n",
    "no_of_images_to_read_in_dev_mode = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data collected in csv file\n",
    "\n",
    "samples = []\n",
    "\n",
    "def read_samples(filename):\n",
    "    with open(filename) as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        first_line = True\n",
    "        for sample in reader:\n",
    "            if(first_line and file_contains_header):\n",
    "                first_line = False\n",
    "                continue\n",
    "            samples.append(sample)\n",
    "            if(dev_mode and len(samples) >= no_of_images_to_read_in_dev_mode):\n",
    "                break\n",
    "\n",
    "\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_forward_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_reverse_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_shoulder_to_road_1_lap/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track2_forward_2_laps/driving_log.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample count is  17355\n",
      "sample count is  17355\n",
      "steering_angles  17355\n",
      "hist  [  407   144   129   247   249   363   446   567   582   437 11030   541\n",
      "   471   400   260   267   267   127   152   269]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n"
     ]
    }
   ],
   "source": [
    "# Print the histogram of the data points\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "samples = shuffle(samples)\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "def visualize_steering_angles_histogram(samples, num_bins = 20):\n",
    "    steering_angles = []\n",
    "\n",
    "    for sample in samples:\n",
    "        steering_angles.append(sample[3])\n",
    "    steering_angles = np.array(steering_angles).astype(np.float)\n",
    "    #print(samples[:][3])\n",
    "    print('steering_angles ', len(steering_angles))\n",
    "    #steering_angles = steering_angles[0:5000]\n",
    "    #print('steering_angles ', len(steering_angles))\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "    avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "    hist, bins = np.histogram(steering_angles, num_bins)\n",
    "\n",
    "    print('hist ', hist)\n",
    "    print('bins ', bins)\n",
    "\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width)\n",
    "    plt.plot((np.min(steering_angles), np.max(steering_angles)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "    #plt.show()\n",
    "    \n",
    "    return \n",
    "\n",
    "num_bins = 20\n",
    "visualize_steering_angles_histogram(samples, num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_angles  7655\n",
      "hist  [ 407  144  129  247  249  363  446  567  582  437 1330  541  471  400\n",
      "  260  267  267  127  152  269]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flatten the data points\n",
    "flattened_samples = []\n",
    "\n",
    "steering_angle_to_flatten = 0\n",
    "avg_samples_per_bin = len(samples)/num_bins\n",
    "count = 0\n",
    "for sample in samples:\n",
    "    if(float(sample[3]) == steering_angle_to_flatten):\n",
    "        if(count <= avg_samples_per_bin):\n",
    "            flattened_samples.append(sample)\n",
    "        count = count+1\n",
    "    else:\n",
    "        flattened_samples.append(sample)\n",
    " \n",
    "#avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "#hist, bins = np.histogram(steering_angles, num_bins)\n",
    "#plt.bar(center, hist, align='center', width=width)\n",
    "#plt.plot((np.min(flattened_samples), np.max(flattened_samples)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "\n",
    "\n",
    "visualize_steering_angles_histogram(flattened_samples)\n",
    "\n",
    "samples = flattened_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# Split the data between training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the brightness of the image\n",
    "def _get_brightnessed_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    random_bright = .25 + np.random.uniform()\n",
    "    img[:,:,2] = img[:,:,2] * random_bright\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training samples is   6124\n",
      "no. of validation samples is   1531\n",
      "calling the train generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5952/6124 [============================>.] - ETA: 1s - loss: 0.1884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6144/6124 [==============================] - 63s - loss: 0.1860 - val_loss: 0.1802\n",
      "Epoch 2/3\n",
      "6144/6124 [==============================] - 65s - loss: 0.1486 - val_loss: 0.1459\n",
      "Epoch 3/3\n",
      "6144/6124 [==============================] - 63s - loss: 0.1438 - val_loss: 0.1069\n",
      "Time Taken to load the images and train the model :  198.55726718902588\n"
     ]
    }
   ],
   "source": [
    "image_shape = (160,320,3)\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    #relative_path = '../CarND-Behavioral-Cloning-P3-data/data/IMG'\n",
    "    relative_path = '../CarND-Behavioral-Cloning-P3-My-Data'\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset: offset+batch_size]\n",
    "            images = []\n",
    "            measurements = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                for i in range(3):\n",
    "                    image_file_name = batch_sample[i].split(':')[-1]\n",
    "\n",
    "                    relative_file_name = relative_path + image_file_name\n",
    "                    relative_file_name = relative_file_name.replace('\\\\','//')\n",
    "                    input_image = cv2.imread(relative_file_name)\n",
    "\n",
    "                    #print(batch_sample[i].split(':'))\n",
    "                    #print('image_file_name ', image_file_name)\n",
    "                    #print('relative_file_name ', relative_file_name)\n",
    "                    #print('input_image file name ', relative_file_name)\n",
    "                    #print('input_image ', input_image)\n",
    "                    #print('input_image.shape ', input_image.shape)\n",
    "\n",
    "                    \n",
    "                    # Modify the brightness of the image\n",
    "                    if np.random.uniform() < 0.5:\n",
    "                        input_image = _get_brightnessed_image(input_image)\n",
    "\n",
    "                    images.append(input_image)\n",
    "\n",
    "                    measurement = float(batch_sample[3])\n",
    "                    correction_factor = 0.2\n",
    "                    if(i == 1):\n",
    "                        measurement = measurement + correction_factor\n",
    "                    elif(i == 2):\n",
    "                        measurement = measurement - correction_factor\n",
    "                    measurements.append(measurement)\n",
    "\n",
    "                    # Augment data by flipping the image and negating the measurement\n",
    "                    images.append(cv2.flip(input_image,1))\n",
    "                    measurements.append(-1.0 * measurement)\n",
    "                    \n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            #import sklearn.utils.shuffle\n",
    "            yield (X_train, y_train)\n",
    "\n",
    "print('no. of training samples is  ', len(train_samples))\n",
    "print('no. of validation samples is  ', len(validation_samples))\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "print(\"calling the train generator\")\n",
    "#print((next(train_generator)))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, MaxPooling2D, Cropping2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(image_shape)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# Lenet Architecture\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(120))\n",
    "#model.add(Dense(84))\n",
    "#model.add(Dense(1))\n",
    "\n",
    "# NVIDIA Architecture\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation = \"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer = 'adam')\n",
    "\n",
    "#model.fit(X_train, y_train, shuffle=True, validation_split=0.2, nb_epoch=5)\n",
    "model.fit_generator(train_generator, samples_per_epoch= len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "print('Time Taken to load the images and train the model : ', time.time() - start_time)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
