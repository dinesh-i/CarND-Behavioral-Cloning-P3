{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.callbacks import ModelCheckpoint, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contains_header = False\n",
    "dev_mode = False\n",
    "no_of_images_to_read_in_dev_mode = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data collected in csv file\n",
    "\n",
    "samples = []\n",
    "\n",
    "def read_samples(filename):\n",
    "    with open(filename) as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        first_line = True\n",
    "        for sample in reader:\n",
    "            if(first_line and file_contains_header):\n",
    "                first_line = False\n",
    "                continue\n",
    "            samples.append(sample)\n",
    "            if(dev_mode and len(samples) >= no_of_images_to_read_in_dev_mode):\n",
    "                break\n",
    "\n",
    "\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_forward_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_reverse_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_shoulder_to_road_1_lap/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track2_forward_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_smooth_curves/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_smooth_curves_2/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_smooth_curves_3/driving_log.csv')\n",
    "#read_samples('../CarND-Behavioral-Cloning-P3-My-Data/udacity_data/data/driving_log.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample count is  22635\n",
      "sample count is  22635\n",
      "steering_angles  22635\n",
      "hist  [  450   159   145   300   317   491   628   812   789   624 14733   646\n",
      "   567   471   310   306   302   142   167   276]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n",
      "avg_samples_per_bin  1131.75\n"
     ]
    }
   ],
   "source": [
    "# Print the histogram of the data points\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "samples = shuffle(samples)\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "def visualize_steering_angles_histogram(samples, num_bins = 20):\n",
    "    steering_angles = []\n",
    "\n",
    "    for sample in samples:\n",
    "        steering_angles.append(sample[3])\n",
    "    steering_angles = np.array(steering_angles).astype(np.float)\n",
    "    #print(samples[:][3])\n",
    "    print('steering_angles ', len(steering_angles))\n",
    "    #steering_angles = steering_angles[0:5000]\n",
    "    #print('steering_angles ', len(steering_angles))\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "    avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "    hist, bins = np.histogram(steering_angles, num_bins)\n",
    "\n",
    "    print('hist ', hist)\n",
    "    print('bins ', bins)\n",
    "    print('avg_samples_per_bin ',avg_samples_per_bin)\n",
    "\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width)\n",
    "    plt.plot((np.min(steering_angles), np.max(steering_angles)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "    #plt.show()\n",
    "    \n",
    "    return \n",
    "\n",
    "num_bins = 20\n",
    "visualize_steering_angles_histogram(samples, num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_angles  8563\n",
      "hist  [450 159 145 300 317 491 628 812 789 624 661 646 567 471 310 306 302 142\n",
      " 167 276]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n",
      "avg_samples_per_bin  428.15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flatten_data_point(samples, bin_left, bin_right, factor_ratio_to_retain = 0.5):\n",
    "    # Flatten the data points\n",
    "    flattened_samples = []\n",
    "\n",
    "    #steering_angle_to_flatten = 0\n",
    "    avg_samples_per_bin = len(samples)/num_bins\n",
    "    count = 0\n",
    "    for sample in samples:\n",
    "        #if(float(sample[3]) == steering_angle_to_flatten):\n",
    "        if(float(sample[3]) >= bin_left and float(sample[3]) < bin_right ):\n",
    "            if(count <= int(avg_samples_per_bin * factor_ratio_to_retain )):\n",
    "                flattened_samples.append(sample)\n",
    "            count = count+1\n",
    "        else:\n",
    "            flattened_samples.append(sample)\n",
    "\n",
    "    #avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "    #hist, bins = np.histogram(steering_angles, num_bins)\n",
    "    #plt.bar(center, hist, align='center', width=width)\n",
    "    #plt.plot((np.min(flattened_samples), np.max(flattened_samples)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "\n",
    "\n",
    "    visualize_steering_angles_histogram(flattened_samples)\n",
    "    return flattened_samples\n",
    "\n",
    "avg_samples_per_bin = len(samples)/num_bins\n",
    "factor_ratio_to_retain = 0.5\n",
    "samples = flatten_data_point(samples, bin_left = 0, bin_right=0.1, factor_ratio_to_retain = 0.45)\n",
    "#samples = flatten_data_point(samples, bin_left = 0.1, bin_right=0.2, factor_ratio_to_retain = 0.8)\n",
    "#samples = flatten_data_point(samples, bin_left = -0.1, bin_right=0, factor_ratio_to_retain = 0.8)\n",
    "#samples = flatten_data_point(samples, bin_left = -0.2, bin_right=-0.1, factor_ratio_to_retain = 0.7)\n",
    "#samples = flatten_data_point(samples, bin_left = -0.3, bin_right=-0.2, factor_ratio_to_retain = 0.5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# Split the data between training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the brightness of the image\n",
    "def _get_brightnessed_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    random_bright = .25 + np.random.uniform()\n",
    "    img[:,:,2] = img[:,:,2] * random_bright\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training samples is   6850\n",
      "no. of validation samples is   1713\n",
      "calling the train generator\n",
      "Epoch 1/7\n",
      "6720/6850 [============================>.] - ETA: 1s - loss: 0.2319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6912/6850 [==============================] - 78s - loss: 0.2298 - val_loss: 0.1969\n",
      "Epoch 2/7\n",
      "6912/6850 [==============================] - 80s - loss: 0.1902 - val_loss: 0.1600\n",
      "Epoch 3/7\n",
      "6912/6850 [==============================] - 83s - loss: 0.1518 - val_loss: 0.1272\n",
      "Epoch 4/7\n",
      "6912/6850 [==============================] - 83s - loss: 0.1376 - val_loss: 0.1392\n",
      "Epoch 5/7\n",
      "6912/6850 [==============================] - 84s - loss: 0.1332 - val_loss: 0.1185\n",
      "Epoch 6/7\n",
      "6924/6850 [==============================] - 150s - loss: 0.1349 - val_loss: 0.1414\n",
      "Epoch 7/7\n",
      "6912/6850 [==============================] - 163s - loss: 0.1209 - val_loss: 0.1285\n",
      "Time Taken to load the images and train the model :  725.2886390686035\n"
     ]
    }
   ],
   "source": [
    "image_shape = (160,320,3)\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    #relative_path = '../CarND-Behavioral-Cloning-P3-data/data/IMG'\n",
    "    relative_path = '../CarND-Behavioral-Cloning-P3-My-Data'\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset: offset+batch_size]\n",
    "            images = []\n",
    "            measurements = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                for i in range(3):\n",
    "                    image_file_name = batch_sample[i].split(':')[-1]\n",
    "\n",
    "                    relative_file_name = relative_path + image_file_name\n",
    "                    relative_file_name = relative_file_name.replace('\\\\','//')\n",
    "                    input_image = cv2.imread(relative_file_name)\n",
    "\n",
    "                    #print(batch_sample[i].split(':'))\n",
    "                    #print('image_file_name ', image_file_name)\n",
    "                    #print('relative_file_name ', relative_file_name)\n",
    "                    #print('input_image file name ', relative_file_name)\n",
    "                    #print('input_image ', input_image)\n",
    "                    #print('input_image.shape ', input_image.shape)\n",
    "\n",
    "                    \n",
    "                    # Modify the brightness of the image\n",
    "                    #if np.random.uniform() < 0.5:\n",
    "                        #input_image = _get_brightnessed_image(input_image)\n",
    "\n",
    "                    images.append(input_image)\n",
    "\n",
    "                    measurement = float(batch_sample[3])\n",
    "                    correction_factor = 0.2\n",
    "                    if(i == 1):\n",
    "                        measurement = measurement + correction_factor\n",
    "                    elif(i == 2):\n",
    "                        measurement = measurement - correction_factor\n",
    "                    measurements.append(measurement)\n",
    "\n",
    "                    # Augment data by flipping the image and negating the measurement\n",
    "                    images.append(cv2.flip(input_image,1))\n",
    "                    measurements.append(-1.0 * measurement)\n",
    "                    \n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            #import sklearn.utils.shuffle\n",
    "            yield (X_train, y_train)\n",
    "\n",
    "print('no. of training samples is  ', len(train_samples))\n",
    "print('no. of validation samples is  ', len(validation_samples))\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "print(\"calling the train generator\")\n",
    "#print((next(train_generator)))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, MaxPooling2D, Cropping2D, Dropout\n",
    "from keras.regularizers import l2, activity_l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(image_shape)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# Lenet Architecture\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(120))\n",
    "#model.add(Dense(84))\n",
    "#model.add(Dense(1))\n",
    "\n",
    "# NVIDIA Architecture\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), border_mode='valid', W_regularizer=l2(0.0005), activation = \"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), border_mode='valid', W_regularizer=l2(0.0005), activation = \"relu\"))\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), border_mode='valid', W_regularizer=l2(0.0005), activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, border_mode='valid', W_regularizer=l2(0.0005), activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, border_mode='valid', W_regularizer=l2(0.0005), activation = \"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer = 'adam')\n",
    "\n",
    "checkpoint = ModelCheckpoint('model_tune_do_elu_{epoch:02d}.h5')\n",
    "\n",
    "#model.fit(X_train, y_train, shuffle=True, validation_split=0.2, nb_epoch=5)\n",
    "model.fit_generator(train_generator, samples_per_epoch= len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=7, callbacks=[checkpoint])\n",
    "\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "print('Time Taken to load the images and train the model : ', time.time() - start_time)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
