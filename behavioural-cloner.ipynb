{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.callbacks import ModelCheckpoint, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contains_header = False\n",
    "dev_mode = False\n",
    "no_of_images_to_read_in_dev_mode = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data collected in csv file\n",
    "\n",
    "samples = []\n",
    "\n",
    "def read_samples(filename):\n",
    "    with open(filename) as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        first_line = True\n",
    "        for sample in reader:\n",
    "            if(first_line and file_contains_header):\n",
    "                first_line = False\n",
    "                continue\n",
    "            samples.append(sample)\n",
    "            if(dev_mode and len(samples) >= no_of_images_to_read_in_dev_mode):\n",
    "                break\n",
    "\n",
    "\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_forward_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_reverse_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_shoulder_to_road_1_lap/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track2_forward_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_smooth_curves/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/udacity_data/data/driving_log.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_file_name  \\track1_forward_2_laps\\IMG\\center_2018_05_19_20_58_22_014.jpg\n",
      "relative_file_name  ../CarND-Behavioral-Cloning-P3-My-Data\\track1_forward_2_laps\\IMG\\center_2018_05_19_20_58_22_014.jpg\n",
      "relative_file_name  ../CarND-Behavioral-Cloning-P3-My-Data//track1_forward_2_laps//IMG//center_2018_05_19_20_58_22_014.jpg\n",
      "input_image.shape  (160, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "relative_path = '../CarND-Behavioral-Cloning-P3-My-Data'\n",
    "#for sample in samples:\n",
    "\n",
    "image_file_name = samples[0][0].split(':')[-1]\n",
    "print('image_file_name ', image_file_name)\n",
    "\n",
    "relative_file_name = relative_path + image_file_name\n",
    "print('relative_file_name ', relative_file_name)\n",
    "relative_file_name = relative_file_name.replace('\\\\','//')\n",
    "print('relative_file_name ', relative_file_name)\n",
    "input_image = cv2.imread(relative_file_name)\n",
    "print('input_image.shape ', input_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample count is  27812\n",
      "sample count is  27812\n",
      "steering_angles  27812\n",
      "hist  [  415   151   138   272   287   483   608   984  1156  1363 17896  1354\n",
      "   660   594   313   294   281   136   155   272]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n"
     ]
    }
   ],
   "source": [
    "# Print the histogram of the data points\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "samples = shuffle(samples)\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "def visualize_steering_angles_histogram(samples, num_bins = 20):\n",
    "    steering_angles = []\n",
    "\n",
    "    for sample in samples:\n",
    "        steering_angles.append(sample[3])\n",
    "    steering_angles = np.array(steering_angles).astype(np.float)\n",
    "    #print(samples[:][3])\n",
    "    print('steering_angles ', len(steering_angles))\n",
    "    #steering_angles = steering_angles[0:5000]\n",
    "    #print('steering_angles ', len(steering_angles))\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "    avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "    hist, bins = np.histogram(steering_angles, num_bins)\n",
    "\n",
    "    print('hist ', hist)\n",
    "    print('bins ', bins)\n",
    "\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width)\n",
    "    plt.plot((np.min(steering_angles), np.max(steering_angles)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "    #plt.show()\n",
    "    \n",
    "    return \n",
    "\n",
    "num_bins = 20\n",
    "visualize_steering_angles_histogram(samples, num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_angles  12515\n",
      "hist  [ 415  151  138  272  287  483  608  984 1156 1363 2599 1354  660  594\n",
      "  313  294  281  136  155  272]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flatten the data points\n",
    "flattened_samples = []\n",
    "\n",
    "steering_angle_to_flatten = 0\n",
    "avg_samples_per_bin = len(samples)/num_bins\n",
    "count = 0\n",
    "for sample in samples:\n",
    "    if(float(sample[3]) == steering_angle_to_flatten):\n",
    "        if(count <= avg_samples_per_bin):\n",
    "            flattened_samples.append(sample)\n",
    "        count = count+1\n",
    "    else:\n",
    "        flattened_samples.append(sample)\n",
    " \n",
    "#avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "#hist, bins = np.histogram(steering_angles, num_bins)\n",
    "#plt.bar(center, hist, align='center', width=width)\n",
    "#plt.plot((np.min(flattened_samples), np.max(flattened_samples)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "\n",
    "\n",
    "visualize_steering_angles_histogram(flattened_samples)\n",
    "\n",
    "samples = flattened_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# Split the data between training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the brightness of the image\n",
    "def _get_brightnessed_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    random_bright = .25 + np.random.uniform()\n",
    "    img[:,:,2] = img[:,:,2] * random_bright\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training samples is   10012\n",
      "no. of validation samples is   2503\n",
      "calling the train generator\n",
      "Epoch 1/5\n",
      " 9984/10012 [============================>.] - ETA: 0s - loss: 0.1119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10176/10012 [==============================] - 115s - loss: 0.1115 - val_loss: 0.0984\n",
      "Epoch 2/5\n",
      "10176/10012 [==============================] - 175s - loss: 0.0931 - val_loss: 0.0821\n",
      "Epoch 3/5\n",
      "10176/10012 [==============================] - 133s - loss: 0.0832 - val_loss: 0.0693\n",
      "Epoch 4/5\n",
      "10176/10012 [==============================] - 119s - loss: 0.0744 - val_loss: 0.0794\n",
      "Epoch 5/5\n",
      "10176/10012 [==============================] - 179s - loss: 0.0730 - val_loss: 0.0835\n",
      "Time Taken to load the images and train the model :  724.7191379070282\n"
     ]
    }
   ],
   "source": [
    "image_shape = (160,320,3)\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    #relative_path = '../CarND-Behavioral-Cloning-P3-data/data/IMG'\n",
    "    relative_path = '../CarND-Behavioral-Cloning-P3-My-Data'\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset: offset+batch_size]\n",
    "            images = []\n",
    "            measurements = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                for i in range(3):\n",
    "                    image_file_name = batch_sample[i].split(':')[-1]\n",
    "\n",
    "                    relative_file_name = relative_path + image_file_name\n",
    "                    relative_file_name = relative_file_name.replace('\\\\','//')\n",
    "                    input_image = cv2.imread(relative_file_name)\n",
    "\n",
    "                    #print(batch_sample[i].split(':'))\n",
    "                    #print('image_file_name ', image_file_name)\n",
    "                    #print('relative_file_name ', relative_file_name)\n",
    "                    #print('input_image file name ', relative_file_name)\n",
    "                    #print('input_image ', input_image)\n",
    "                    #print('input_image.shape ', input_image.shape)\n",
    "\n",
    "                    \n",
    "                    # Modify the brightness of the image\n",
    "                    #if np.random.uniform() < 0.5:\n",
    "                        #input_image = _get_brightnessed_image(input_image)\n",
    "\n",
    "                    images.append(input_image)\n",
    "\n",
    "                    measurement = float(batch_sample[3])\n",
    "                    correction_factor = 0.2\n",
    "                    if(i == 1):\n",
    "                        measurement = measurement + correction_factor\n",
    "                    elif(i == 2):\n",
    "                        measurement = measurement - correction_factor\n",
    "                    measurements.append(measurement)\n",
    "\n",
    "                    # Augment data by flipping the image and negating the measurement\n",
    "                    images.append(cv2.flip(input_image,1))\n",
    "                    measurements.append(-1.0 * measurement)\n",
    "                    \n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            #import sklearn.utils.shuffle\n",
    "            yield (X_train, y_train)\n",
    "\n",
    "print('no. of training samples is  ', len(train_samples))\n",
    "print('no. of validation samples is  ', len(validation_samples))\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "print(\"calling the train generator\")\n",
    "#print((next(train_generator)))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, MaxPooling2D, Cropping2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(image_shape)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# Lenet Architecture\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(120))\n",
    "#model.add(Dense(84))\n",
    "#model.add(Dense(1))\n",
    "\n",
    "# NVIDIA Architecture\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation = \"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer = 'adam')\n",
    "\n",
    "checkpoint = ModelCheckpoint('model_u_sc_{epoch:02d}.h5')\n",
    "\n",
    "#model.fit(X_train, y_train, shuffle=True, validation_split=0.2, nb_epoch=5)\n",
    "model.fit_generator(train_generator, samples_per_epoch= len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=5, callbacks=[checkpoint])\n",
    "\n",
    "\n",
    "model.save('model_u_sc.h5')\n",
    "\n",
    "print('Time Taken to load the images and train the model : ', time.time() - start_time)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
