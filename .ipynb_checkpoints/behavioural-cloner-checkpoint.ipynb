{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contains_header = False\n",
    "dev_mode = False\n",
    "no_of_images_to_read_in_dev_mode = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data collected in csv file\n",
    "\n",
    "samples = []\n",
    "\n",
    "def read_samples(filename):\n",
    "    with open(filename) as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        first_line = True\n",
    "        for sample in reader:\n",
    "            if(first_line and file_contains_header):\n",
    "                first_line = False\n",
    "                continue\n",
    "            samples.append(sample)\n",
    "            if(dev_mode and len(samples) >= no_of_images_to_read_in_dev_mode):\n",
    "                break\n",
    "\n",
    "\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_forward_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_reverse_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_shoulder_to_road_1_lap/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track2_forward_2_laps/driving_log.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample count is  17355\n",
      "sample count is  17355\n",
      "steering_angles  17355\n",
      "hist  [  407   144   129   247   249   363   446   567   582   437 11030   541\n",
      "   471   400   260   267   267   127   152   269]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n"
     ]
    }
   ],
   "source": [
    "# Print the histogram of the data points\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "samples = shuffle(samples)\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "def visualize_steering_angles_histogram(samples, num_bins = 20):\n",
    "    steering_angles = []\n",
    "\n",
    "    for sample in samples:\n",
    "        steering_angles.append(sample[3])\n",
    "    steering_angles = np.array(steering_angles).astype(np.float)\n",
    "    #print(samples[:][3])\n",
    "    print('steering_angles ', len(steering_angles))\n",
    "    #steering_angles = steering_angles[0:5000]\n",
    "    #print('steering_angles ', len(steering_angles))\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "    avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "    hist, bins = np.histogram(steering_angles, num_bins)\n",
    "\n",
    "    print('hist ', hist)\n",
    "    print('bins ', bins)\n",
    "\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width)\n",
    "    plt.plot((np.min(steering_angles), np.max(steering_angles)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "    #plt.show()\n",
    "    \n",
    "    return \n",
    "\n",
    "num_bins = 20\n",
    "visualize_steering_angles_histogram(samples, num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_angles  6979\n",
      "hist  [407 144 129 247 249 363 446 567 582 437 654 541 471 400 260 267 267 127\n",
      " 152 269]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flatten the data points\n",
    "flattened_samples = []\n",
    "\n",
    "steering_angle_to_flatten = 0\n",
    "avg_samples_per_bin = len(samples)/num_bins\n",
    "count = 0\n",
    "for sample in samples:\n",
    "    if(float(sample[3]) == steering_angle_to_flatten):\n",
    "        if(count <= avg_samples_per_bin/2):\n",
    "            flattened_samples.append(sample)\n",
    "        count = count+1\n",
    "    else:\n",
    "        flattened_samples.append(sample)\n",
    " \n",
    "#avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "#hist, bins = np.histogram(steering_angles, num_bins)\n",
    "#plt.bar(center, hist, align='center', width=width)\n",
    "#plt.plot((np.min(flattened_samples), np.max(flattened_samples)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "\n",
    "\n",
    "visualize_steering_angles_histogram(flattened_samples)\n",
    "\n",
    "samples = flattened_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# Split the data between training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the brightness of the image\n",
    "def _get_brightnessed_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    random_bright = .25 + np.random.uniform()\n",
    "    img[:,:,2] = img[:,:,2] * random_bright\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training samples is   5583\n",
      "no. of validation samples is   1396\n",
      "calling the train generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5568/5583 [============================>.] - ETA: 0s - loss: 0.2137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5583 [==============================] - 60s - loss: 0.2116 - val_loss: 0.1692\n",
      "Epoch 2/3\n",
      "5760/5583 [==============================] - 61s - loss: 0.1548 - val_loss: 0.1434\n",
      "Epoch 3/3\n",
      "5760/5583 [==============================] - 60s - loss: 0.1425 - val_loss: 0.1426\n",
      "Time Taken to load the images and train the model :  189.12250304222107\n"
     ]
    }
   ],
   "source": [
    "image_shape = (160,320,3)\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    #relative_path = '../CarND-Behavioral-Cloning-P3-data/data/IMG'\n",
    "    relative_path = '../CarND-Behavioral-Cloning-P3-My-Data'\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset: offset+batch_size]\n",
    "            images = []\n",
    "            measurements = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                for i in range(3):\n",
    "                    image_file_name = batch_sample[i].split(':')[-1]\n",
    "\n",
    "                    relative_file_name = relative_path + image_file_name\n",
    "                    relative_file_name = relative_file_name.replace('\\\\','//')\n",
    "                    input_image = cv2.imread(relative_file_name)\n",
    "\n",
    "                    #print(batch_sample[i].split(':'))\n",
    "                    #print('image_file_name ', image_file_name)\n",
    "                    #print('relative_file_name ', relative_file_name)\n",
    "                    #print('input_image file name ', relative_file_name)\n",
    "                    #print('input_image ', input_image)\n",
    "                    #print('input_image.shape ', input_image.shape)\n",
    "\n",
    "                    \n",
    "                    # Modify the brightness of the image\n",
    "                    if np.random.uniform() < 0.5:\n",
    "                        input_image = _get_brightnessed_image(input_image)\n",
    "\n",
    "                    images.append(input_image)\n",
    "\n",
    "                    measurement = float(batch_sample[3])\n",
    "                    correction_factor = 0.2\n",
    "                    if(i == 1):\n",
    "                        measurement = measurement + correction_factor\n",
    "                    elif(i == 2):\n",
    "                        measurement = measurement - correction_factor\n",
    "                    measurements.append(measurement)\n",
    "\n",
    "                    # Augment data by flipping the image and negating the measurement\n",
    "                    images.append(cv2.flip(input_image,1))\n",
    "                    measurements.append(-1.0 * measurement)\n",
    "                    \n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            #import sklearn.utils.shuffle\n",
    "            yield (X_train, y_train)\n",
    "\n",
    "print('no. of training samples is  ', len(train_samples))\n",
    "print('no. of validation samples is  ', len(validation_samples))\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "print(\"calling the train generator\")\n",
    "#print((next(train_generator)))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, MaxPooling2D, Cropping2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(image_shape)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# Lenet Architecture\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(120))\n",
    "#model.add(Dense(84))\n",
    "#model.add(Dense(1))\n",
    "\n",
    "# NVIDIA Architecture\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation = \"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer = 'adam')\n",
    "\n",
    "#model.fit(X_train, y_train, shuffle=True, validation_split=0.2, nb_epoch=5)\n",
    "model.fit_generator(train_generator, samples_per_epoch= len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "print('Time Taken to load the images and train the model : ', time.time() - start_time)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
