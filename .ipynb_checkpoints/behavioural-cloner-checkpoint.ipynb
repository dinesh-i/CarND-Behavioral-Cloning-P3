{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.callbacks import ModelCheckpoint, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contains_header = False\n",
    "dev_mode = False\n",
    "no_of_images_to_read_in_dev_mode = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data collected in csv file\n",
    "\n",
    "samples = []\n",
    "\n",
    "def read_samples(filename):\n",
    "    with open(filename) as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        first_line = True\n",
    "        for sample in reader:\n",
    "            if(first_line and file_contains_header):\n",
    "                first_line = False\n",
    "                continue\n",
    "            samples.append(sample)\n",
    "            if(dev_mode and len(samples) >= no_of_images_to_read_in_dev_mode):\n",
    "                break\n",
    "\n",
    "\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_forward_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_reverse_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_shoulder_to_road_1_lap/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track2_forward_2_laps/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/track1_smooth_curves/driving_log.csv')\n",
    "read_samples('../CarND-Behavioral-Cloning-P3-My-Data/udacity_data/data/driving_log.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_file_name  \\track1_forward_2_laps\\IMG\\center_2018_05_19_20_58_22_014.jpg\n",
      "relative_file_name  ../CarND-Behavioral-Cloning-P3-My-Data\\track1_forward_2_laps\\IMG\\center_2018_05_19_20_58_22_014.jpg\n",
      "relative_file_name  ../CarND-Behavioral-Cloning-P3-My-Data//track1_forward_2_laps//IMG//center_2018_05_19_20_58_22_014.jpg\n",
      "input_image.shape  (160, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "relative_path = '../CarND-Behavioral-Cloning-P3-My-Data'\n",
    "#for sample in samples:\n",
    "\n",
    "image_file_name = samples[0][0].split(':')[-1]\n",
    "print('image_file_name ', image_file_name)\n",
    "\n",
    "relative_file_name = relative_path + image_file_name\n",
    "print('relative_file_name ', relative_file_name)\n",
    "relative_file_name = relative_file_name.replace('\\\\','//')\n",
    "print('relative_file_name ', relative_file_name)\n",
    "input_image = cv2.imread(relative_file_name)\n",
    "print('input_image.shape ', input_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample count is  19776\n",
      "sample count is  19776\n",
      "steering_angles  19776\n",
      "hist  [  411   150   136   266   276   421   530   684   683   525 12811   573\n",
      "   499   422   271   282   276   135   155   270]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n"
     ]
    }
   ],
   "source": [
    "# Print the histogram of the data points\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "samples = shuffle(samples)\n",
    "print('sample count is ', len(samples))\n",
    "\n",
    "def visualize_steering_angles_histogram(samples, num_bins = 20):\n",
    "    steering_angles = []\n",
    "\n",
    "    for sample in samples:\n",
    "        steering_angles.append(sample[3])\n",
    "    steering_angles = np.array(steering_angles).astype(np.float)\n",
    "    #print(samples[:][3])\n",
    "    print('steering_angles ', len(steering_angles))\n",
    "    #steering_angles = steering_angles[0:5000]\n",
    "    #print('steering_angles ', len(steering_angles))\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "    avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "    hist, bins = np.histogram(steering_angles, num_bins)\n",
    "\n",
    "    print('hist ', hist)\n",
    "    print('bins ', bins)\n",
    "\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width)\n",
    "    plt.plot((np.min(steering_angles), np.max(steering_angles)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "    #plt.show()\n",
    "    \n",
    "    return \n",
    "\n",
    "num_bins = 20\n",
    "visualize_steering_angles_histogram(samples, num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_angles  8438\n",
      "hist  [ 411  150  136  266  276  421  530  684  683  525 1473  573  499  422\n",
      "  271  282  276  135  155  270]\n",
      "bins  [-1.  -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3\n",
      "  0.4  0.5  0.6  0.7  0.8  0.9  1. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flatten the data points\n",
    "flattened_samples = []\n",
    "\n",
    "steering_angle_to_flatten = 0\n",
    "avg_samples_per_bin = len(samples)/num_bins\n",
    "count = 0\n",
    "for sample in samples:\n",
    "    if(float(sample[3]) == steering_angle_to_flatten):\n",
    "        if(count <= avg_samples_per_bin):\n",
    "            flattened_samples.append(sample)\n",
    "        count = count+1\n",
    "    else:\n",
    "        flattened_samples.append(sample)\n",
    " \n",
    "#avg_samples_per_bin = len(steering_angles)/num_bins\n",
    "#hist, bins = np.histogram(steering_angles, num_bins)\n",
    "#plt.bar(center, hist, align='center', width=width)\n",
    "#plt.plot((np.min(flattened_samples), np.max(flattened_samples)), (avg_samples_per_bin, avg_samples_per_bin), 'k-')\n",
    "\n",
    "\n",
    "visualize_steering_angles_histogram(flattened_samples)\n",
    "\n",
    "samples = flattened_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# Split the data between training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the brightness of the image\n",
    "def _get_brightnessed_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    random_bright = .25 + np.random.uniform()\n",
    "    img[:,:,2] = img[:,:,2] * random_bright\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training samples is   6750\n",
      "no. of validation samples is   1688\n",
      "calling the train generator\n",
      "Epoch 1/5\n",
      "6720/6750 [============================>.] - ETA: 0s - loss: 0.1627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tavant/miniconda3/envs/carnd-term1-cpu/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6912/6750 [==============================] - 78s - loss: 0.1632 - val_loss: 0.1385\n",
      "Epoch 2/5\n",
      "6912/6750 [==============================] - 85s - loss: 0.1106 - val_loss: 0.1148\n",
      "Epoch 3/5\n",
      "6912/6750 [==============================] - 78s - loss: 0.1004 - val_loss: 0.0920\n",
      "Epoch 4/5\n",
      "6912/6750 [==============================] - 78s - loss: 0.1082 - val_loss: 0.0973\n",
      "Epoch 5/5\n",
      "6912/6750 [==============================] - 79s - loss: 0.0975 - val_loss: 0.0936\n",
      "Time Taken to load the images and train the model :  401.62183904647827\n"
     ]
    }
   ],
   "source": [
    "image_shape = (160,320,3)\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    #relative_path = '../CarND-Behavioral-Cloning-P3-data/data/IMG'\n",
    "    relative_path = '../CarND-Behavioral-Cloning-P3-My-Data'\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset: offset+batch_size]\n",
    "            images = []\n",
    "            measurements = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                for i in range(3):\n",
    "                    image_file_name = batch_sample[i].split(':')[-1]\n",
    "\n",
    "                    relative_file_name = relative_path + image_file_name\n",
    "                    relative_file_name = relative_file_name.replace('\\\\','//')\n",
    "                    input_image = cv2.imread(relative_file_name)\n",
    "\n",
    "                    #print(batch_sample[i].split(':'))\n",
    "                    #print('image_file_name ', image_file_name)\n",
    "                    #print('relative_file_name ', relative_file_name)\n",
    "                    #print('input_image file name ', relative_file_name)\n",
    "                    #print('input_image ', input_image)\n",
    "                    #print('input_image.shape ', input_image.shape)\n",
    "\n",
    "                    \n",
    "                    # Modify the brightness of the image\n",
    "                    #if np.random.uniform() < 0.5:\n",
    "                        #input_image = _get_brightnessed_image(input_image)\n",
    "\n",
    "                    images.append(input_image)\n",
    "\n",
    "                    measurement = float(batch_sample[3])\n",
    "                    correction_factor = 0.2\n",
    "                    if(i == 1):\n",
    "                        measurement = measurement + correction_factor\n",
    "                    elif(i == 2):\n",
    "                        measurement = measurement - correction_factor\n",
    "                    measurements.append(measurement)\n",
    "\n",
    "                    # Augment data by flipping the image and negating the measurement\n",
    "                    images.append(cv2.flip(input_image,1))\n",
    "                    measurements.append(-1.0 * measurement)\n",
    "                    \n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(measurements)\n",
    "            #import sklearn.utils.shuffle\n",
    "            yield (X_train, y_train)\n",
    "\n",
    "print('no. of training samples is  ', len(train_samples))\n",
    "print('no. of validation samples is  ', len(validation_samples))\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "print(\"calling the train generator\")\n",
    "#print((next(train_generator)))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, MaxPooling2D, Cropping2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(image_shape)))\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# Lenet Architecture\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Convolution2D(6,5,5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(120))\n",
    "#model.add(Dense(84))\n",
    "#model.add(Dense(1))\n",
    "\n",
    "# NVIDIA Architecture\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation = \"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation = \"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer = 'adam')\n",
    "\n",
    "checkpoint = ModelCheckpoint('model{epoch:02d}.h5')\n",
    "\n",
    "#model.fit(X_train, y_train, shuffle=True, validation_split=0.2, nb_epoch=5)\n",
    "model.fit_generator(train_generator, samples_per_epoch= len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=5, callbacks=[checkpoint])\n",
    "\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "print('Time Taken to load the images and train the model : ', time.time() - start_time)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
